{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b260f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Import Libraries --------#\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import mlflow\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3423c37a-4b59-4a1f-93f8-4ef70f490869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Import Modules from project--------#\n",
    "import encoding as enc\n",
    "from model import Net, Net_thesis, Net_project\n",
    "import functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4211d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPUs available. Using CPU instead.\n"
     ]
    }
   ],
   "source": [
    "#-------- Set Device --------#\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "else:\n",
    "    print('No GPUs available. Using CPU instead.')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd5adc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Seeds --------#\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b993fa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file ../data/train\\P1_labels.npz\n",
      "Read file ../data/train\\P2_labels.npz\n",
      "Read file ../data/train\\P3_labels.npz\n",
      "Read file ../data/train\\P4_labels.npz\n",
      "Read file ../data/validation\\P5_labels.npz\n",
      "\n",
      "\n",
      "target_list 5\n",
      "\n",
      "\n",
      "Size of file 1 500\n",
      "Size of file 2 500\n",
      "Size of file 3 500\n",
      "Size of file 4 500\n",
      "Size of file 5 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------- Import target Dataset --------#             \n",
    "\n",
    "target_list = []\n",
    "\n",
    "import glob\n",
    "for index in range(4):\n",
    "    for fp in glob.glob(\"../data/train/*{}*labels.npz\".format(index+1)):\n",
    "        print(\"Read file\", fp)\n",
    "        targets = np.load(fp)[\"arr_0\"]\n",
    "        target_list.append(targets[0:500])\n",
    "    \n",
    "for fp in glob.glob(\"../data/validation/*5*labels.npz\"):\n",
    "    print(\"Read file\", fp)\n",
    "    targets = np.load(fp)[\"arr_0\"]\n",
    "    target_list.append(targets[0:500])\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"target_list\", len(target_list))\n",
    "print(\"\\n\")\n",
    "\n",
    "data_partitions = len(target_list)\n",
    "for i in range(len(target_list)):\n",
    "    print(\"Size of file\", i+1, len(target_list[i]))\n",
    "\n",
    "del targets\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9897fc5",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#-------- Select the network you would like to use -------#\n",
    "\n",
    "CNN = False # ONLY CNN\n",
    "CNN_RNN = True # CNN + RNN\n",
    "\n",
    "# Hyperparameters to fine-tune\n",
    "embedding = \"esm_1b\"\n",
    "numHN=32\n",
    "numFilter=100\n",
    "dropOutRate=0.1\n",
    "learning_rate=0.001\n",
    "weight_decay = 0.0001\n",
    "\n",
    "#for ml-flow\n",
    "name_experiment = \"PCA\"\n",
    "\n",
    "\n",
    "##--- parameters fixed\n",
    "keep_energy=True\n",
    "bat_size = 128\n",
    "num_classes=1\n",
    "epochs = 100\n",
    "patience=10\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f46dc5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1 is uploaded. Size: 1530\n",
      "File 2 is uploaded. Size: 1170\n",
      "File 3 is uploaded. Size: 1480\n",
      "File 4 is uploaded. Size: 1540\n",
      "File 5 is uploaded. Size: 1210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting embedding of data\n",
    "\n",
    "#create directory to fetch/store embedded\n",
    "embedding_dir= '../data/embeddedFiles/'\n",
    "data_list_enc = list()\n",
    "\n",
    "try:\n",
    "    os.mkdir(embedding_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#try to fecth if already exist\n",
    "if embedding == \"Baseline\":   \n",
    "    pass\n",
    "else:\n",
    "    try:\n",
    "        for i in range(5):\n",
    "            #infile = open(embedding_dir + 'esm-energies-file-updated-{}.pkl'.format(i+1), 'rb')\n",
    "            infile = open(embedding_dir + 'dataset-esm-1b_{}.pkl'.format(i), 'rb')\n",
    "            enc = pickle.load(infile)\n",
    "            data_list_enc.append(enc[0:100])\n",
    "            print(\"File\", i+1, \"is uploaded. Size:\", len(enc))\n",
    "            infile.close()        \n",
    "        '''\n",
    "        infile = open(embedding_dir+'dataset-{}'.format(embedding), 'rb')\n",
    "        data_list_enc =  pickle.load(infile)\n",
    "        infile.close()\n",
    "        '''\n",
    "    #if no prior file, embedding code needs to be run before:\n",
    "    except:\n",
    "        print(\"Embedded file not found\")\n",
    "\n",
    "#del enc\n",
    "gc.collect()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e9dce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Apply PCA to the dataset -------#\n",
    "\n",
    "PCA_do = True\n",
    "pca_dir = '../data/PCA_models/'\n",
    "\n",
    "try:\n",
    "    os.mkdir(pca_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if PCA_do:\n",
    "    matrix_train = np.empty((0, len(data_list_enc[0][0][0]))); total_observations = 0\n",
    "    for partition in range(3):\n",
    "        n_obser, partition_matrix = func.prepare_data_pca(data_list_enc[partition])\n",
    "        matrix_train = np.append(matrix_train, partition_matrix, axis = 0)\n",
    "        total_observations += n_obser\n",
    "\n",
    "    var_vector, number_components, model, fitted_train = func.run_PCA(matrix_train)\n",
    "    # and now this model will be applied to validation dataset by running command model.transfrom(X_val)\n",
    "    \n",
    "    try:\n",
    "        infile = open(pca_dir+'model_{}.pkl'.format(embedding), 'rb')\n",
    "        pickle.load(infile)\n",
    "        infile.close()\n",
    "\n",
    "    #if no prior file, save the model as a pickle:\n",
    "    except:\n",
    "        with open(pca_dir + 'model_{}.pkl'.format(embedding), 'wb') as f:\n",
    "            pickle.dump(model, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee2556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: 300 420 20\n",
      "Validation set shape: 100 420 20\n",
      "Test set shape: 100 420 20\n"
     ]
    }
   ],
   "source": [
    "#-------- Get train, validation and test datasets with PCA applied -------#\n",
    "\n",
    "X_train = func.back_to_original_size(fitted_train, [total_observations, len(data_list_enc[0][0]), number_components])\n",
    "y_train = np.concatenate(target_list[0:3])\n",
    "nsamples, nx, ny = X_train.shape\n",
    "print(\"Training set shape:\", nsamples,nx,ny)\n",
    "\n",
    "n_obser, matrix_valid = func.prepare_data_pca(data_list_enc[3])\n",
    "X_valid = model.transform(matrix_valid)\n",
    "X_valid = func.back_to_original_size(X_valid, [n_obser, len(data_list_enc[0][0]), number_components])\n",
    "y_valid = target_list[3]\n",
    "nsamples, nx, ny = X_valid.shape\n",
    "print(\"Validation set shape:\", nsamples,nx,ny)\n",
    "\n",
    "n_obser, matrix_test = func.prepare_data_pca(data_list_enc[4])\n",
    "X_test = model.transform(matrix_test)\n",
    "X_test = func.back_to_original_size(X_test, [n_obser, len(data_list_enc[0][0]), number_components])\n",
    "y_test = target_list[4]\n",
    "nsamples, nx, ny = X_test.shape\n",
    "print(\"Test set shape:\", nsamples,nx,ny) \n",
    "\n",
    "# features and residues\n",
    "features = list(range(ny))\n",
    "residues = list(range(nx)) \n",
    "n_features = len(features)\n",
    "input_size = len(residues)\n",
    "\n",
    "del data_list_enc\n",
    "gc.collect()\n",
    "\n",
    "# Dataloader\n",
    "train_ds = []\n",
    "for i in range(len(X_train)):\n",
    "    train_ds.append([np.transpose(X_train[i][:,features]), y_train[i]])\n",
    "val_ds = []\n",
    "for i in range(len(X_valid)):\n",
    "    val_ds.append([np.transpose(X_valid[i][:,features]), y_valid[i]])\n",
    "test_ds = []\n",
    "for i in range(len(X_test)):\n",
    "    test_ds.append([np.transpose(X_test[i][:,features]), y_test[i]])\n",
    "    \n",
    "del X_train, X_test, y_train, y_test \n",
    "gc.collect()\n",
    "\n",
    "train_ldr = torch.utils.data.DataLoader(train_ds,batch_size=bat_size, shuffle=True)\n",
    "val_ldr = torch.utils.data.DataLoader(val_ds,batch_size=bat_size, shuffle=True)\n",
    "test_ldr = torch.utils.data.DataLoader(test_ds,batch_size=len(test_ds), shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1153ff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "embedding esm_1b\n",
      "numHN 32\n",
      "numFilter 100\n",
      "dropOutRate 0.1\n",
      "keep_energy True\n",
      "num_classes 1\n",
      "learning_rate 0.001\n",
      "bat_size 128\n",
      "patience 10\n",
      "criterion BCEWithLogitsLoss()\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5d2443ab34fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m                         amsgrad=True,)\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_auc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_targs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_targs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_project\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ldr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ldr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ldr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\enric\\Documents\\Bioinformatics\\3rd semester\\Deep learning\\Project\\02456_TCR-pMHC\\scripts\\functions.py\u001b[0m in \u001b[0;36mtrain_project\u001b[1;34m(net, optimizer, train_ldr, val_ldr, test_ldr, X_valid, epochs, criterion, early_stop)\u001b[0m\n\u001b[0;32m    411\u001b[0m             \u001b[0mtrain_acc_cur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_targs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[0mvalid_acc_cur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_targs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m             \u001b[0mtrain_auc_cur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_targs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m             \u001b[0mvalid_auc_cur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_targs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         return _average_binary_score(partial(_binary_roc_auc_score,\n\u001b[0m\u001b[0;32m    543\u001b[0m                                              max_fpr=max_fpr),\n\u001b[0;32m    544\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;34m\"\"\"Binary roc auc score.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[0;32m    328\u001b[0m                          \"is not defined in that case.\")\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "###############################\n",
    "###    CNN+RNN (thesis)     ###\n",
    "###############################\n",
    "start = time.time()\n",
    "\n",
    "print(\"Parameters:\")\n",
    "print(\"embedding\", embedding)\n",
    "print(\"numHN\", numHN)\n",
    "print(\"numFilter\", numFilter)\n",
    "print(\"dropOutRate\", dropOutRate)\n",
    "print(\"keep_energy\", keep_energy)\n",
    "print(\"num_classes\", num_classes)\n",
    "print(\"learning_rate\", learning_rate)\n",
    "print(\"bat_size\", bat_size)\n",
    "print(\"patience\", patience)\n",
    "print(\"criterion\", criterion)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#-------- Train --------#\n",
    "\n",
    "# Initialize network\n",
    "net = Net_project(num_classes=num_classes, \n",
    "            n_features=n_features, \n",
    "            numHN=numHN, \n",
    "            numFilter=numFilter,\n",
    "            dropOutRate=dropOutRate).to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate,\n",
    "                        weight_decay=weight_decay,\n",
    "                        amsgrad=True,)\n",
    "\n",
    "train_acc, train_losses, train_auc, valid_acc, valid_losses, valid_auc, val_preds, val_targs, test_preds, test_targs, test_loss, test_acc, test_auc = func.train_project(net, optimizer, train_ldr, val_ldr, test_ldr, X_valid, epochs, criterion, patience)\n",
    "\n",
    "\n",
    "print(\"Done in\", round((time.time()-start)/60,2), \"mins.\" )\n",
    "\n",
    "print(\"test_loss, test_acc, test_auc:\")\n",
    "print(test_loss.item(), \",\", test_acc[0], \",\", test_auc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12ec0ebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6922fc0b71f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#-------- Performance --------#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "#-------- Performance --------#\n",
    "\n",
    "epoch = np.arange(1,len(train_losses)+1)\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_losses, 'r', epoch, valid_losses, 'b')\n",
    "plt.legend(['Train Loss','Validation Loss'])\n",
    "plt.xlabel('Epoch'), plt.ylabel('Loss')\n",
    "\n",
    "epoch = np.arange(1,len(train_auc)+1)\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_auc, 'r', epoch, valid_auc, 'b')\n",
    "plt.legend(['Train AUC','Validation AUC'])\n",
    "plt.xlabel('Epoch'), plt.ylabel('AUC')\n",
    "\n",
    "epoch = np.arange(1,len(train_acc)+1)\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_acc, 'r', epoch, valid_acc, 'b')\n",
    "plt.legend(['Train Accuracy','Validation Accuracy'])\n",
    "plt.xlabel('Epoch'), plt.ylabel('Acc')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#-------- Save results --------#\n",
    "\n",
    "results_dir = '../results'\n",
    "\n",
    "try:\n",
    "    os.mkdir(results_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "plots_dir = '../results/plots'\n",
    "\n",
    "try:\n",
    "    os.mkdir(plots_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "results = pd.DataFrame(list(zip( (int(x) for x in test_targs), (int(x) for x in test_preds))),columns =['target', 'pred'])\n",
    "\n",
    "\n",
    "results.to_csv('../results/PCA_emb_{}_HN_{}_nFilt_{}_do_{}_energ_{}.csv'.format(embedding,numHN,numFilter,int(dropOutRate*10), keep_energy), index=False)\n",
    "\n",
    "\n",
    "#-------- Performance Evaluation --------#\n",
    "# The results change every time we train, we should check why (maybe we missed something or did wrong with the seeds?)\n",
    "\n",
    "print(\"Number of principal components for PCA\", number_components)\n",
    "print(\"AUC: \", roc_auc_score(results['target'], results['pred']))\n",
    "print(\"MCC: \", matthews_corrcoef(results['target'], results['pred']))\n",
    "\n",
    "confusion_matrix = pd.crosstab(results['target'], results['pred'], rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "plt.show()\n",
    "\n",
    "# Plot roc curve\n",
    "\n",
    "fpr, tpr, thres = roc_curve(results['target'], results['pred'])\n",
    "print('AUC: {:.3f}'.format(roc_auc_score(results['target'], results['pred'])))\n",
    "\n",
    "print( len([i for i, (a, b) in enumerate(zip(results['pred'], results['target'])) if a != b]))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# roc curve\n",
    "plt.plot(fpr, tpr, \"b\", label='ROC Curve')\n",
    "plt.plot([0,1],[0,1], \"k--\", label='Random Guess')\n",
    "plt.xlabel(\"false positive rate\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"ROC curve\")\n",
    "\n",
    "\n",
    "plt.savefig('../results/plots/PCA_emb_{}_HN_{}_nFilt_{}_do_{}_energ_{}_ROC.png'.format(embedding,numHN,numFilter,int(dropOutRate*10), keep_energy))\n",
    "plt.show()\n",
    "\n",
    "AUC = roc_auc_score(results['target'], results['pred'])\n",
    "MCC = matthews_corrcoef(results['target'], results['pred'])\n",
    "ACC = accuracy_score(results['target'], results['pred'])\n",
    "print(\"AUC: \", AUC)\n",
    "print(\"MCC: \", MCC)\n",
    "print(\"ACC: \", ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8218f21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Default\n",
      "Experiment_id: 0\n",
      "Artifact Location: file:///home/shannara/DL_02456/dayana_run/scripts/mlruns/0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'AUC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a0087acc6b16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'learning rate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Weight decay'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test AUC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAUC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test MCC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMCC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test ACC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mACC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AUC' is not defined"
     ]
    }
   ],
   "source": [
    "#storing values\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "experiment_id = mlflow.set_experiment(name_experiment)\n",
    "experiment = mlflow.get_experiment(experiment_id)\n",
    "\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param('embedding', embedding) \n",
    "    mlflow.log_param('Number principal components', number_components)\n",
    "    mlflow.log_param('Hidden Neurons', numHN)\n",
    "    mlflow.log_param('filters CNN', numFilter)\n",
    "    mlflow.log_param('Dropout rate', dropOutRate)\n",
    "    mlflow.log_param('learning rate', learning_rate)\n",
    "    mlflow.log_param('Weight decay', weight_decay)\n",
    "    mlflow.log_metric('test AUC', AUC)\n",
    "    mlflow.log_metric('test MCC', MCC)\n",
    "    mlflow.log_metric('test ACC', ACC)\n",
    "    \n",
    "    mlflow.log_metric('train ACC', train_acc[-1])\n",
    "    mlflow.log_metric('train AUC', train_auc[-1])\n",
    "    mlflow.log_metric('valid ACC', valid_acc[-1])\n",
    "    mlflow.log_metric('valid AUC', valid_auc[-1])\n",
    "\n",
    "from csv import writer\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print('embedding', embedding)\n",
    "print('principal components',number_components) \n",
    "print('Hidden Neurons', numHN)\n",
    "print('filters CNN', numFilter)\n",
    "print('Dropout rate', dropOutRate)\n",
    "print('learning rate', learning_rate)\n",
    "print('Weight decay', weight_decay)\n",
    "\n",
    "print('test AUC', AUC)\n",
    "print('test MCC', MCC)\n",
    "print('test ACC', ACC)\n",
    "\n",
    "print('train ACC', train_acc[-1])\n",
    "print('train AUC', train_auc[-1])\n",
    "print('valid ACC', valid_acc[-1])\n",
    "print('valid AUC', valid_auc[-1])\n",
    "\n",
    "\n",
    "#List = ['embedding', 'numHN', 'numFilter', 'dropOutRate', 'learning_rate', 'weight_decay', 'AUC', 'MCC', 'ACC', 'train_acc', 'train_auc', 'valid_acc', 'valid_auc' ]\n",
    "List = [embedding, number_components, numHN, numFilter, dropOutRate, learning_rate, weight_decay, AUC, MCC, ACC, train_acc[-1], train_auc[-1], valid_acc[-1], valid_auc[-1] ]\n",
    "\n",
    "with open('../results/PCA_results.csv', 'a') as f_object:\n",
    "    writer_object = writer(f_object)\n",
    "  \n",
    "    writer_object.writerow(List)\n",
    "  \n",
    "    f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f5714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
