{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbafe379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Import Libraries --------#\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f761caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Import Modules from project--------#\n",
    "import encoding as enc\n",
    "from model import Net, Net_th\n",
    "import functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82776f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPUs available. Using CPU instead.\n"
     ]
    }
   ],
   "source": [
    "#-------- Set Device --------#\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "else:\n",
    "    print('No GPUs available. Using CPU instead.')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e57e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Seeds --------#\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85bf12aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Directories --------#\n",
    "\n",
    "DATADIR = '/data/'\n",
    "TRAINDIR = '../data/train'\n",
    "VALIDATIONDIR = '../data/validation'\n",
    "MATRICES = '/data/Matrices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f3fd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/train already unzipped.\n",
      "../data/validation already unzipped.\n",
      "Train directory:\n",
      "\n",
      " P1_input.npz\n",
      "P1_labels.npz\n",
      "P2_input.npz\n",
      "P2_labels.npz\n",
      "P3_input.npz\n",
      "P3_labels.npz\n",
      "P4_input.npz\n",
      "P4_labels.npz\n",
      "__MACOSX \n",
      "\n",
      "\n",
      "Validation directory:\n",
      "\n",
      " P4_input.npz\n",
      "P4_labels.npz\n",
      "__MACOSX\n"
     ]
    }
   ],
   "source": [
    "#-------- Unzip Train --------#\n",
    "\n",
    "if len(os.listdir(TRAINDIR)) != 0:\n",
    "        print(\"{} already unzipped.\".format(TRAINDIR))\n",
    "else:\n",
    "    !unzip ../data/train.zip -d ../data/train\n",
    "\n",
    "    \n",
    "#-------- Unzip Validation --------#\n",
    "\n",
    "\n",
    "if len(os.listdir(VALIDATIONDIR)) != 0:\n",
    "        print(\"{} already unzipped.\".format(VALIDATIONDIR))\n",
    "else:\n",
    "    !unzip ../data/validation.zip -d ../data/validation\n",
    "    \n",
    "print('Train directory:\\n\\n', '\\n'.join(str(p) for p in os.listdir(TRAINDIR)), '\\n\\n')\n",
    "print('Validation directory:\\n\\n','\\n'.join(str(p) for p in os.listdir(VALIDATIONDIR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2cf985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "Training set shape: 4174 420 54\n",
      "Val set shape: 1532 420 54\n",
      "Percent positive samples in train: 24.96406324868232\n",
      "Percent positive samples in val: 25.0\n",
      "\n",
      "NOTE:\n",
      "Setting batch-size to 64\n"
     ]
    }
   ],
   "source": [
    "#-------- Import Dataset --------#             #TO UPDATE: NO REPEAT P4 AND CONSERVE PARTITION FOR CROSS VAL\n",
    "\n",
    "data_list = []\n",
    "target_list = []\n",
    "\n",
    "import glob\n",
    "for fp in glob.glob(\"../data/train/*input.npz\"):\n",
    "    data = np.load(fp)[\"arr_0\"]\n",
    "    targets = np.load(fp.replace(\"input\", \"labels\"))[\"arr_0\"]\n",
    "    data_list.append(data)\n",
    "    target_list.append(targets)\n",
    "    \n",
    "print(len(data_list))\n",
    "print(len(target_list))\n",
    "\n",
    "X_train = np.concatenate(data_list[ :-1])\n",
    "y_train = np.concatenate(target_list[:-1])\n",
    "nsamples, nx, ny = X_train.shape\n",
    "print(\"Training set shape:\", nsamples,nx,ny)\n",
    "\n",
    "X_val = np.concatenate(data_list[-1: ])\n",
    "y_val = np.concatenate(target_list[-1: ])\n",
    "nsamples, nx, ny = X_val.shape\n",
    "print(\"Val set shape:\", nsamples,nx,ny)\n",
    "\n",
    "p_neg = len(y_train[y_train == 1])/len(y_train)*100\n",
    "print(\"Percent positive samples in train:\", p_neg)\n",
    "\n",
    "p_pos = len(y_val[y_val == 1])/len(y_val)*100\n",
    "print(\"Percent positive samples in val:\", p_pos)\n",
    "\n",
    "# make the data set into one dataset that can go into dataloader\n",
    "train_ds = []\n",
    "for i in range(len(X_train)):\n",
    "    train_ds.append([np.transpose(X_train[i]), y_train[i]])\n",
    "\n",
    "val_ds = []\n",
    "for i in range(len(X_val)):\n",
    "    val_ds.append([np.transpose(X_val[i]), y_val[i]])\n",
    "\n",
    "bat_size = 64\n",
    "print(\"\\nNOTE:\\nSetting batch-size to\", bat_size)\n",
    "train_ldr = torch.utils.data.DataLoader(train_ds,batch_size=bat_size, shuffle=True)\n",
    "val_ldr = torch.utils.data.DataLoader(val_ds,batch_size=bat_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d3fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Hyperparameters to fine-tune\n",
    "embedding = \"Baseline\"\n",
    "numHN=64\n",
    "numFilter=100\n",
    "dropOutRate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad696bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed hyperparameters\n",
    "features = list(range(54))  #to be redefined\n",
    "residues = list(range(416))  #to be redefined\n",
    "num_classes = 1\n",
    "learning_rate = 0.001\n",
    "n_features = len(features)\n",
    "input_size = len(residues)\n",
    "bat_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d00982c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: 4174 420 54\n",
      "Validation set shape: 1532 420 54\n"
     ]
    }
   ],
   "source": [
    "#data load\n",
    "\n",
    "\n",
    "#-------- Train --------#\n",
    "X_train = np.concatenate(data_list[ :-1])\n",
    "y_train = np.concatenate(target_list[:-1])\n",
    "nsamples, nx, ny = X_train.shape\n",
    "print(\"Training set shape:\", nsamples,nx,ny)\n",
    "\n",
    "X_valid = np.concatenate(data_list[-1: ])\n",
    "y_valid = np.concatenate(target_list[-1: ])\n",
    "nsamples, nx, ny = X_valid.shape\n",
    "print(\"Validation set shape:\", nsamples,nx,ny)\n",
    "\n",
    "# Dataloader\n",
    "train_ds = []\n",
    "for i in range(len(X_train)):\n",
    "    train_ds.append([np.transpose(X_train[i][:,features]), y_train[i]])\n",
    "val_ds = []\n",
    "for i in range(len(X_valid)):\n",
    "    val_ds.append([np.transpose(X_valid[i][:,features]), y_valid[i]])\n",
    "train_ldr = torch.utils.data.DataLoader(train_ds,batch_size=bat_size, shuffle=True)\n",
    "val_ldr = torch.utils.data.DataLoader(val_ds,batch_size=bat_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "548ce233",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'functions' has no attribute 'train_th'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f47683aa624a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_auc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_targs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_th\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ldr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ldr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#-------- Performance --------#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'functions' has no attribute 'train_th'"
     ]
    }
   ],
   "source": [
    "# Initialize network\n",
    "net = Net_project(num_classes=num_classes, \n",
    "             n_features=n_features, \n",
    "             numHN=numHN, \n",
    "             numFilter=numFilter,\n",
    "             dropOutRate=dropOutRate).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate,\n",
    "                        weight_decay=0.0005,\n",
    "                        amsgrad=True,\n",
    "                        )\n",
    "\n",
    "#train\n",
    "train_acc, train_losses, train_auc, valid_acc, valid_losses, valid_auc, val_preds, val_targs = func.train_th(net, optimizer, train_ldr, val_ldr, [], [], epochs, criterion)\n",
    "\n",
    "#-------- Performance --------#\n",
    "epoch = np.arange(1,len(train_losses)+1)\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_losses, 'r', epoch, valid_losses, 'b')\n",
    "plt.legend(['Train Loss','Validation Loss'])\n",
    "plt.xlabel('Epoch'), plt.ylabel('Loss')\n",
    "\n",
    "epoch = np.arange(1,len(train_auc)+1)\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_auc, 'r', epoch, valid_auc, 'b')\n",
    "plt.legend(['Train AUC','Validation AUC'])\n",
    "plt.xlabel('Epoch'), plt.ylabel('AUC')\n",
    "\n",
    "epoch = np.arange(1,len(train_acc)+1)\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_acc, 'r', epoch, valid_acc, 'b')\n",
    "plt.legend(['Train Accuracy','Validation Accuracy'])\n",
    "plt.xlabel('Epoch'), plt.ylabel('Acc')\n",
    "plt.show()\n",
    "\n",
    "#save results\n",
    "results = pd.DataFrame(list(zip( (int(x) for x in val_targs), (int(x) for x in val_preds))),columns =['target', 'pred'])\n",
    "print(results)\n",
    "\n",
    "#metrics\n",
    "AUC = roc_auc_score(results['target'], results['pred'])\n",
    "MCC = matthews_corrcoef(results['target'], results['pred'])\n",
    "print(\"AUC: \", AUC)\n",
    "print(\"MCC: \", MCC)\n",
    "\n",
    "confusion_matrix = pd.crosstab(results['target'], results['pred'], rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "plt.show()\n",
    "\n",
    "print( len([i for i, (a, b) in enumerate(zip(results['pred'], results['target'])) if a != b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing values\n",
    "with mlflow.start:run():\n",
    "    mlflow.log_param('embedding', embedding)\n",
    "    mlflow.log_metric('AUC', AUC)\n",
    "    mlflow.log_metric('MCC', MCC)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
