{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c127b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Import Libraries --------#\n",
    "import torch\n",
    "#import esm\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "#import mlflow\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import torch.nn as nn\n",
    "#import seaborn as sn\n",
    "#import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "#from sklearn.metrics import matthews_corrcoef\n",
    "#import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "#import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "#from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "673cbaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting utils\n",
      "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
      "Installing collected packages: utils\n",
      "Successfully installed utils-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3edd891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DGraphDTAscripts as sp\n",
    "import DGraphDTAdata_process as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c382444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_aa(one_hot):\n",
    "    mapping = dict(zip(range(20),\"ACDEFGHIKLMNPQRSTVWY\"))\n",
    "    try:\n",
    "        index = one_hot.index(1)\n",
    "        return mapping[index]     \n",
    "    except:\n",
    "        return 'X'\n",
    "\n",
    "def reverseOneHot(encoding):\n",
    "    \"\"\"\n",
    "    Converts one-hot encoded array back to string sequence\n",
    "    \"\"\"\n",
    "    seq=''\n",
    "    for i in range(len(encoding)):\n",
    "            if return_aa(encoding[i].tolist()) != 'X':\n",
    "                seq+=return_aa(encoding[i].tolist())\n",
    "    return seq\n",
    "\n",
    "def extract_sequences(dataset_X, merge=False):\n",
    "    \"\"\"\n",
    "    Return DataFrame with MHC, peptide and TCR a/b sequences from\n",
    "    one-hot encoded complex sequences in dataset X\n",
    "    \"\"\"\n",
    "    mhc_sequences = [reverseOneHot(arr[0:179,0:20]) for arr in dataset_X]\n",
    "    pep_sequences = [reverseOneHot(arr[179:192,0:20]) for arr in dataset_X] ## 190 or 192 ????\n",
    "    tcr_sequences = [reverseOneHot(arr[192:,0:20]) for arr in dataset_X]\n",
    "    all_sequences = [reverseOneHot(arr[:,0:20]) for arr in dataset_X]\n",
    "\n",
    "    if merge:\n",
    "        df_sequences = pd.DataFrame({\"all\": all_sequences})\n",
    "\n",
    "    else:\n",
    "        df_sequences = pd.DataFrame({\"MHC\":mhc_sequences,\n",
    "                                 \"peptide\":pep_sequences,\n",
    "                                 \"TCR\":tcr_sequences})\n",
    "        \n",
    "    return df_sequences       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee267f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- Directories --------#\n",
    "\n",
    "DATADIR = '02456_TCR-pMHC/data/'\n",
    "TRAINDIR = '02456_TCR-pMHC/data/train'\n",
    "VALIDATIONDIR = '02456_TCR-pMHC/data/validation'\n",
    "MATRICES = '02456_TCR-pMHC/data/Matrices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7d4fabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02456_TCR-pMHC/data/train already unzipped.\n",
      "02456_TCR-pMHC/data/validation already unzipped.\n",
      "Train directory:\n",
      "\n",
      " P1_input.npz\n",
      "P1_labels.npz\n",
      "P2_input.npz\n",
      "P2_labels.npz\n",
      "P3_input.npz\n",
      "P3_labels.npz\n",
      "P4_input.npz\n",
      "P4_labels.npz\n",
      "__MACOSX \n",
      "\n",
      "\n",
      "Validation directory:\n",
      "\n",
      " P4_input.npz\n",
      "P4_labels.npz\n",
      "__MACOSX\n"
     ]
    }
   ],
   "source": [
    "#-------- Unzip Train --------#\n",
    "\n",
    "try:\n",
    "    if len(os.listdir(TRAINDIR)) != 0:\n",
    "        print(\"{} already unzipped.\".format(TRAINDIR))\n",
    "except:\n",
    "    !unzip ../data/train.zip -d ../data/train\n",
    "\n",
    "    \n",
    "#-------- Unzip Validation --------#\n",
    "\n",
    "try:\n",
    "    if len(os.listdir(VALIDATIONDIR)) != 0:\n",
    "        print(\"{} already unzipped.\".format(VALIDATIONDIR))\n",
    "except:\n",
    "    !unzip ../data/validation.zip -d ../data/validation\n",
    "    \n",
    "print('Train directory:\\n\\n', '\\n'.join(str(p) for p in os.listdir(TRAINDIR)), '\\n\\n')\n",
    "print('Validation directory:\\n\\n','\\n'.join(str(p) for p in os.listdir(VALIDATIONDIR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7286433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 5\n",
      "Size of file 0 1526\n",
      "Size of file 1 1168\n",
      "Size of file 2 1480\n",
      "Size of file 3 1532\n",
      "Size of file 4 1532\n"
     ]
    }
   ],
   "source": [
    "#-------- Import Dataset --------#\n",
    "\n",
    "data_list = []\n",
    "target_list = []\n",
    "\n",
    "import glob\n",
    "for fp in glob.glob(\"02456_TCR-pMHC/data/train/*input.npz\"):\n",
    "    data = np.load(fp)[\"arr_0\"]\n",
    "    targets = np.load(fp.replace(\"input\", \"labels\"))[\"arr_0\"]\n",
    "    data_list.append(data)\n",
    "    target_list.append(targets)\n",
    "    \n",
    "for fp in glob.glob(\"02456_TCR-pMHC/data/validation/*input.npz\"):\n",
    "    data = np.load(fp)[\"arr_0\"]\n",
    "    targets = np.load(fp.replace(\"input\", \"labels\"))[\"arr_0\"]\n",
    "    data_list.append(data)\n",
    "    target_list.append(targets)\n",
    "    \n",
    "data_partitions = len(data_list)\n",
    "\n",
    "print(\"Number of files:\", data_partitions)\n",
    "\n",
    "for i in range(data_partitions):\n",
    "    print(\"Size of file\", i, len(data_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b15cde3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 5\n",
      "Sequences are extracted\n",
      "Sequences are extracted\n",
      "Sequences are extracted\n",
      "Sequences are extracted\n",
      "                                                    MHC    peptide  \\\n",
      "0     GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GLCTLVAML   \n",
      "1     GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GILGFVFTL   \n",
      "2     GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GLCTLVAML   \n",
      "3     GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GILGFVFTL   \n",
      "4     GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GILGFVFTL   \n",
      "...                                                 ...        ...   \n",
      "1527  GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  NLVPMVATV   \n",
      "1528  GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  NLVPMVATV   \n",
      "1529  GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GLCTLVAML   \n",
      "1530  GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GLCTLVAML   \n",
      "1531  GSHSMRYFFTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRME...  GILGFVFTL   \n",
      "\n",
      "                                                    TCR  \n",
      "0     VEQHPSTLSVQEGDSAVIKCTYSDSASNYFPWYKQELGKGPQLIID...  \n",
      "1     TQTQPGMFVQEKEAVTLDCTYDTSDPSYGLFWYKQPSSGEMIFLIY...  \n",
      "2     QVEQSPQSLIILEGKNCTLQCNYTVSPFSNLRWYKQDTGRGPVSLT...  \n",
      "3     QVEQSPPDLILQEGANSTLRCNFSDSVNNLQWFHQNPWGQLINLFY...  \n",
      "4     QPSTVASSEGAVVEIFCNHSVSNAYNFFWYLHFPGCAPRLLVKGSK...  \n",
      "...                                                 ...  \n",
      "1527  EQSPQFLSIQEGENLTVYCNSSSVFSSLQWYRQEPGEGPVLLVTVV...  \n",
      "1528  QSVTQLGSHVSVSEGALVLLRCNYSSSVPPYLFWYVQYPNQGLQLL...  \n",
      "1529  VQEGEDFTTYCNSSTTLSNIQWYKQRPGGHPVFLIQLVKSGEVKKK...  \n",
      "1530  VQEGEDFTTYCNSSTTLSNIQWYKQRPGGHPVFLIQLVKSGEVKKK...  \n",
      "1531  QSVTQLGSHVSVSEGALVLLRCNYSSSVPPYLFWYVQYPNQGLQLL...  \n",
      "\n",
      "[1532 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#-------- Encode ALL --------#\n",
    "\n",
    "count=0\n",
    "\n",
    "batch = 5 #### DEBUGGED\n",
    "\n",
    "print(\"batch:\", batch)\n",
    "\n",
    "for dataset in data_list[:-1]: ## last file\n",
    "\n",
    "    dataset = dataset\n",
    "    count += 1\n",
    "\n",
    "    #print(\"\\nWorking on file\", count, \"- size:\", len(dataset))\n",
    "    x_enc = extract_sequences(dataset, merge=False)\n",
    "    print(\"Sequences are extracted\")\n",
    "    \n",
    "print(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced3360e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
